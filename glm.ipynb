{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score, average_precision_score, f1_score, classification_report, accuracy_score,confusion_matrix, silhouette_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.chdir(\"/Users/yj.noh/Documents/GitHub\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"prj-ML-model-LT_OV30/modeling_data.csv\", encoding = \"cp949\")\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 건물 정보 없는 데이터 삭제 \n",
    "filtered_data = data.dropna(subset=['pick_건물용도', 'dlvry_건물용도'])\n",
    "print(filtered_data.shape) #44,644 \n",
    "print(filtered_data['outcome'].value_counts()) # 38,816, 5,828 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlvry_지하층수 음수로\n",
    "# filtered_data['dlvry_지하층수'] = pd.to_numeric(filtered_data['dlvry_지하층수'], errors='coerce')\n",
    "# filtered_data['dlvry_지상층수'] = pd.to_numeric(filtered_data['dlvry_지상층수'], errors='coerce')\n",
    "# filtered_data['pick_floor'] = pd.to_numeric(filtered_data['pick_floor'], errors='coerce')\n",
    "\n",
    "filtered_data['dlvry_지하층수'] = filtered_data['dlvry_지하층수'].apply(lambda x: -x)\n",
    "#print(filtered_data.head())\n",
    "print(filtered_data.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. pick_건물용도/ dlvry_건물용도 : 개수 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data['pick_건물용도'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정리\n",
    "values_to_replace = ['위락시설', '문화시설', '종교시설', '체육시설','위험물저장및처리시설', '자동차관련시설']\n",
    "filtered_data['pick_건물용도'] = data['pick_건물용도'].replace(values_to_replace, '기타시설')\n",
    "print(filtered_data['pick_건물용도'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data['dlvry_건물용도'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = filtered_data['dlvry_건물용도'].value_counts()\n",
    "\n",
    "threshold = 100\n",
    "filtered_data['dlvry_건물용도'] = filtered_data['dlvry_건물용도'].apply(lambda x: '기타시설' if value_counts[x] <= threshold else x)\n",
    "\n",
    "filtered_data['dlvry_건물용도'] = filtered_data['dlvry_건물용도'].replace('교육연구시설', '교육시설')\n",
    "filtered_data['dlvry_건물용도'] = filtered_data['dlvry_건물용도'].replace('공공용시설', '공공시설')\n",
    "\n",
    "print(filtered_data['dlvry_건물용도'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. dlvry_지상층수 /지하층수 : dlvry_건물용도 median 값 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values = filtered_data.dropna().groupby('dlvry_건물용도')[['dlvry_지상층수', 'dlvry_지하층수']].median()\n",
    "mean_values = filtered_data.dropna().groupby('dlvry_건물용도')[['dlvry_지상층수', 'dlvry_지하층수']].mean()\n",
    "\n",
    "print(\"Median Values:\")\n",
    "print(median_values)\n",
    "\n",
    "print(\"\\nMean Values:\")\n",
    "print(mean_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na 값을 중앙값으로 채우기\n",
    "filtered_data['dlvry_지상층수'].fillna(filtered_data['dlvry_건물용도'].map(median_values['dlvry_지상층수']), inplace=True)\n",
    "filtered_data['dlvry_지하층수'].fillna(filtered_data['dlvry_건물용도'].map(median_values['dlvry_지하층수']), inplace=True)\n",
    "\n",
    "print(filtered_data.describe())\n",
    "print(filtered_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3.  pick_floor, dlvry_지상층수, dlvry_지하층수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data['pick_floor'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data['dlvry_지하층수'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data['dlvry_지상층수'].value_counts())\n",
    "print(filtered_data['dlvry_지상층수'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_floor(value):\n",
    "    if value < 0:\n",
    "        return '지하'\n",
    "    elif 0 <= value <= 5:\n",
    "        return '저층'\n",
    "    elif 6 <= value <= 10 :\n",
    "        return '중층'\n",
    "    elif 11 <= value <= 15 : \n",
    "        return '중상층'\n",
    "    elif 16 <= value <= 29 :\n",
    "        return '고층'\n",
    "    elif 30 <= value <= 49 :\n",
    "        return '준초고층'\n",
    "    elif 50 <= value:\n",
    "        return '초고층'\n",
    "\n",
    "filtered_data['pick_floor'] = filtered_data['pick_floor'].apply(categorize_floor)\n",
    "filtered_data['dlvry_지상층수'] = filtered_data['dlvry_지상층수'].apply(categorize_floor)\n",
    "\n",
    "print(filtered_data['dlvry_지상층수'].value_counts())\n",
    "print(filtered_data['pick_floor'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. pick_rgn2_nm, dlvry_rgn2_nm, dlvry_rgn3_nm 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data['dlvry_rgn2_nm'].value_counts())\n",
    "print(filtered_data['dlvry_rgn3_nm'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data.shape) #44,644\n",
    "print(filtered_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = filtered_data[[ 'reg_hour', 'ord_price','actual_dlvry_distance', 'pick_floor', \n",
    "                         'pick_category', 'pick_건물용도','dlvry_지상층수', 'dlvry_지하층수',\n",
    "                         'dlvry_건물용도','day_of_week', 'is_holiday', '기온', 'dlvry_rgn2_nm', 'outcome'\n",
    "                        ]]\n",
    "dataset.isna().sum()\n",
    "dataset.to_csv('prj-ML-model-LT_OV30/modeling_data_final.csv', index= False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['outcome'].value_counts())\n",
    "print(dataset['outcome'].isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. factor 변수 / one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category  \n",
    "for col in ['reg_hour','pick_floor',  'pick_category', 'pick_건물용도','dlvry_지상층수','dlvry_건물용도',\n",
    "            'day_of_week', 'is_holiday','dlvry_rgn2_nm', 'outcome' ] : \n",
    "    dataset[col] = dataset[col].astype('category')\n",
    "\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['reg_hour','pick_floor',  'pick_category', 'pick_건물용도','dlvry_지상층수','dlvry_건물용도',\n",
    "            'day_of_week', 'is_holiday','dlvry_rgn2_nm' ] \n",
    "encoder = OneHotEncoder()\n",
    "onehot = pd.DataFrame(encoder.fit_transform(dataset[var]).toarray(), columns=encoder.get_feature_names_out(var), index = dataset.index)\n",
    "dataset = pd.concat([onehot, dataset.drop(columns=var)], axis=1)\n",
    "\n",
    "print(dataset.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. train/test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_counts = dataset['outcome'].value_counts()\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.25, stratify = dataset['outcome'], random_state=1234)\n",
    "\n",
    "train_outcome_counts = train_set['outcome'].value_counts()\n",
    "test_outcome_counts = test_set['outcome'].value_counts()\n",
    "\n",
    "print(train_outcome_counts)\n",
    "print(test_outcome_counts)\n",
    "\n",
    "print(train_set.shape) #33483\n",
    "print(test_set.shape) #11161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(columns=['outcome'])\n",
    "y_train = train_set['outcome']\n",
    "\n",
    "X_test = test_set.drop(columns=['outcome'])\n",
    "y_test = test_set['outcome']\n",
    "\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set.seed(1234)\n",
    "# train_ratio = 0.75\n",
    "# total_samples = dataset.shape[0]\n",
    "# train_samples = int(train_ratio * total_samples)\n",
    "# train_set = dataset[:train_samples]\n",
    "# test_set = dataset[train_samples:]\n",
    "\n",
    "# print(train_set.shape) #33483\n",
    "# print(test_set.shape) #11161"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['ord_price', 'actual_dlvry_distance', 'dlvry_지하층수', '기온']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train[num_vars] = scaler.fit_transform(X_train[num_vars])\n",
    "X_test[num_vars] = scaler.transform(X_test[num_vars])\n",
    "\n",
    "#print(X_train.head())\n",
    "print(X_train.shape) #33483\n",
    "print(X_test.shape) #11161"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. modeling - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(data):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = data.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# 다중 공선성 확인\n",
    "vif_result = calculate_vif(X_train)\n",
    "print(vif_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_1 = sm.GLM(y_train, X_train, family = sm.families.Binomial())\n",
    "glm1_fit = glm_1.fit()\n",
    "print(glm1_fit.summary())\n",
    "\n",
    "joblib.dump(glm1_fit,'prj-ML-model-LT_OV30/glm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = glm1_fit.predict(X_test)\n",
    "\n",
    "threshold = 0.5 # cut-off 값 \n",
    "y_pred_binary = (y_pred > threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nAccuracy:\", accuracy) #0.87\n",
    "print(\"Sensitivity (True Positive Rate):\", sensitivity) # 0.18\n",
    "print(\"Specificity (True Negative Rate):\", specificity) # 0.98\n",
    "\n",
    "test = conf_matrix[1,1] / (conf_matrix[0, 1] + conf_matrix[1, 1])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape) #11,161                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_model = LogisticRegression(penalty = 'none')\n",
    "# cv_scores = cross_val_score(logit_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "# mean_cv_accuracy = cv_scores.mean()\n",
    "# print(\"Cross-Validation Mean Accuracy:\", mean_cv_accuracy)\n",
    "\n",
    "# logit_model.fit(X_train, y_train)\n",
    "# print(\"Model Coefficients:\", logit_model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = sm.add_constant(X_train) \n",
    "# logit_model = sm.Logit(y_train, X_train)\n",
    "# result = logit_model.fit()\n",
    "\n",
    "# print(result.summary())\n",
    "\n",
    "# X_test = sm.add_constant(X_test) \n",
    "# y_pred = result.predict(X_test)  \n",
    "\n",
    "# y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "# accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "# sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "# specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# print(\"\\nAccuracy:\", accuracy)\n",
    "# print(\"Sensitivity (True Positive Rate):\", sensitivity)\n",
    "# print(\"Specificity (True Negative Rate):\", specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm_2 = LogisticRegression(penalty='none')\n",
    "# glm_2.fit(X_train, y_train)\n",
    "\n",
    "# variable_names = X_train.columns\n",
    "# coef = glm_2.coef_[0]\n",
    "\n",
    "# coef_table = pd.DataFrame({'Variable': variable_names, 'Coefficient': coef})\n",
    "\n",
    "# logit_model = sm.Logit(y_train, X_train)\n",
    "# result = logit_model.fit()\n",
    "# p_values = result.pvalues\n",
    "# coef_table['p-value'] = p_values\n",
    "\n",
    "# print(coef_table)\n",
    "# pred_glm = glm_2.predict(X_test)\n",
    "# class_report = classification_report(y_test, pred_glm)\n",
    "# print(class_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_silhouette_scores(data, method='kmeans', param_init='random', param_n_init=10, param_max_iter=300):\n",
    "    clusters_range = range(2, 15)\n",
    "    results = []\n",
    "\n",
    "    for i in clusters_range:\n",
    "        if method == 'kmeans':\n",
    "            clusterer = KMeans(n_clusters=i, init=param_init, n_init=param_n_init, max_iter=param_max_iter, random_state=0)\n",
    "        elif method == 'agglomerative':\n",
    "            clusterer = AgglomerativeClustering(n_clusters=i)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid method. Choose 'kmeans' or 'agglomerative'.\")\n",
    "\n",
    "        cluster_labels = clusterer.fit_predict(data)\n",
    "        silhouette_avg = silhouette_score(data, cluster_labels)\n",
    "        results.append([i, silhouette_avg])\n",
    "\n",
    "    result = pd.DataFrame(results, columns=[\"n_clusters\", \"silhouette_score\"])\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.heatmap(pd.pivot_table(result, index=\"n_clusters\", values=\"silhouette_score\"),annot=True, linewidths=.5, fmt='.3f', cmap=sns.cm._rocket_lut)\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"Silhouette Scores for {method.capitalize()} Clustering\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = y_pred.to_numpy().reshape(-1, 1)\n",
    "\n",
    "visualize_silhouette_scores(data, method='kmeans')\n",
    "visualize_silhouette_scores(data, method='agglomerative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = y_pred.to_numpy().reshape(-1, 1)\n",
    "n = 5\n",
    "\n",
    "kmeans = KMeans(n_clusters=n)\n",
    "kmeans_clusters = kmeans.fit_predict(X)\n",
    "\n",
    "agglomerative = AgglomerativeClustering(n_clusters=n)\n",
    "agglomerative_clusters = agglomerative.fit_predict(X)\n",
    "\n",
    "kmeans_cluster_centers = kmeans.cluster_centers_\n",
    "agg_cluster_centers = np.array([X[agglomerative_clusters == i].mean(axis=0) for i in range(n)])\n",
    "\n",
    "# 데이터 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.scatter(X, y_pred, c=y_pred, cmap='viridis')\n",
    "plt.title('True Clusters')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y_pred')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.scatter(X, y_pred, c=kmeans_clusters, cmap='viridis')\n",
    "#plt.scatter(kmeans_cluster_centers, [y_pred.mean()] * len(kmeans_cluster_centers), c='red', marker='x', s=100, label='Cluster Centers')\n",
    "#plt.title('K-Means Clusters')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y_pred')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.scatter(X, y_pred, c=agglomerative_clusters, cmap='viridis')\n",
    "#plt.scatter(agg_cluster_centers, [y_pred.mean()] * len(agg_cluster_centers), c='red', marker='x', s=100, label='Cluster Centers')\n",
    "#plt.title('Agglomerative Clusters')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y_pred')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_silhouette_score = silhouette_score(X, kmeans_clusters)\n",
    "agglomerative_silhouette_score = silhouette_score(X, agglomerative_clusters)\n",
    "\n",
    "print(f\"K-Means Silhouette Score: {kmeans_silhouette_score:.2f}\")\n",
    "print(f\"Agglomerative Silhouette Score: {agglomerative_silhouette_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_set, y_pred, pd.DataFrame(kmeans_clusters, columns=['KMeansCluster']),\n",
    "                       pd.DataFrame(agglomerative_clusters, columns=['AgglomerativeCluster'])], axis=1)\n",
    "\n",
    "print(test_data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 최근 3일 서초구 배차건 대입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"prj-ML-model-LT_OV30/new_data_final.csv\", encoding=\"utf-8\")\n",
    "print(new_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data.isna().sum())\n",
    "print(new_data.shape) #18213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[['dlvry_rgn1_nm', 'dlvry_rgn2_nm', 'dlvry_rgn3_nm', 'etc']] = new_data['dlvry_address'].str.split(' ', n=3, expand=True)\n",
    "\n",
    "# dlvry_지하층수 음수로\n",
    "new_data['dlvry_지하층수']  = new_data['dlvry_지하층수'].apply(lambda x: -x)\n",
    "print(new_data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-1. pick_건물용도/dlvry_건물용도 : 개수 축소 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['pick_건물용도'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정리\n",
    "values_to_replace = ['위락시설', '문화시설', '종교시설', '체육시설','위험물저장및처리시설', '자동차관련시설','운수시설']\n",
    "new_data['pick_건물용도'] = new_data['pick_건물용도'].replace(values_to_replace, '기타시설')\n",
    "print(new_data['pick_건물용도'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['dlvry_건물용도'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_counts = new_data['dlvry_건물용도'].value_counts()\n",
    "\n",
    "threshold = 100\n",
    "new_data['dlvry_건물용도'] = new_data['dlvry_건물용도'].apply(lambda x: '기타시설' if new_counts[x] <= threshold else x)\n",
    "\n",
    "new_data['dlvry_건물용도'] = new_data['dlvry_건물용도'].replace('교육연구시설', '교육시설')\n",
    "new_data['dlvry_건물용도'] = new_data['dlvry_건물용도'].replace('공공용시설', '공공시설')\n",
    "\n",
    "print(new_data['dlvry_건물용도'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-3. dlvry_지상층수/지하층수 : dlvry_건물용도별 median 값 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values =new_data.dropna().groupby('dlvry_건물용도')[['dlvry_지상층수', 'dlvry_지하층수']].median()\n",
    "mean_values = new_data.dropna().groupby('dlvry_건물용도')[['dlvry_지상층수', 'dlvry_지하층수']].mean()\n",
    "\n",
    "#print(median_values)\n",
    "#print(mean_values)\n",
    "\n",
    "# na 값을 중앙값으로 채우기\n",
    "new_data['dlvry_지상층수'].fillna(new_data['dlvry_건물용도'].map(median_values['dlvry_지상층수']), inplace=True)\n",
    "new_data['dlvry_지하층수'].fillna(new_data['dlvry_건물용도'].map(median_values['dlvry_지하층수']), inplace=True)\n",
    "\n",
    "#print(new_data.describe())\n",
    "print(new_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['pick_floor'] = new_data['pick_floor'].apply(categorize_floor)\n",
    "new_data['dlvry_지상층수'] = new_data['dlvry_지상층수'].apply(categorize_floor)\n",
    "\n",
    "print(new_data['dlvry_지상층수'].value_counts())\n",
    "print(new_data['pick_floor'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-4. new_data 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data.shape) #18,213\n",
    "print(new_data.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_df = new_data[['reg_hour', 'ord_price','actual_dlvry_distance', 'pick_floor', \n",
    "                         'pick_category', 'pick_건물용도','dlvry_지상층수', 'dlvry_지하층수',\n",
    "                         'dlvry_건물용도','day_of_week', 'is_holiday', '기온', 'dlvry_rgn2_nm'\n",
    "                        ]]\n",
    "new_model_df.isna().sum()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-5. factor 변수 encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['reg_hour','pick_floor',  'pick_category', 'pick_건물용도','dlvry_지상층수','dlvry_건물용도',\n",
    "            'day_of_week', 'is_holiday','dlvry_rgn2_nm', 'outcome' ] : \n",
    "    new_model_df[col] = new_model_df[col].astype('category')\n",
    "\n",
    "print(new_model_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['reg_hour','pick_floor',  'pick_category', 'pick_건물용도','dlvry_지상층수','dlvry_건물용도',\n",
    "            'day_of_week', 'is_holiday','dlvry_rgn2_nm' ] \n",
    "encoder = OneHotEncoder()\n",
    "onehot = pd.DataFrame(encoder.fit_transform(new_model_df[var]).toarray(), columns=encoder.get_feature_names_out(var), index = new_model_df.index)\n",
    "new_model_df = pd.concat([onehot, new_model_df.drop(columns=var)], axis=1)\n",
    "\n",
    "print(new_model_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric scale\n",
    "new_model_df[num_vars] = scaler.transform(new_model_df[num_vars])\n",
    "print(new_model_df.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-6. modeling 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = glm1_fit.predict(new_model_df)\n",
    "print(y_pred_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
